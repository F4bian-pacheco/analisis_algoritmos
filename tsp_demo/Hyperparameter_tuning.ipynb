{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZoneP11Jdo+T4rW0iFWXt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherna90/analisis_algoritmos/blob/master/tsp_demo/Hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU7YHcrHfm2M"
      },
      "source": [
        "# Simulated Annealing Hyperaparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT-aJyMrQvH6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "import scipy.stats as stats\n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# get some data\n",
        "X, y = load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "# build a classifier\n",
        "clf = SGDClassifier(loss='log',fit_intercept=True,shuffle=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtiHV79fTPF1",
        "outputId": "7f61554d-7f30-49a2-8183-f679d3830d4e"
      },
      "source": [
        "clf.get_params()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.0001,\n",
              " 'average': False,\n",
              " 'class_weight': None,\n",
              " 'early_stopping': False,\n",
              " 'epsilon': 0.1,\n",
              " 'eta0': 0.0,\n",
              " 'fit_intercept': True,\n",
              " 'l1_ratio': 0.15,\n",
              " 'learning_rate': 'optimal',\n",
              " 'loss': 'log',\n",
              " 'max_iter': 1000,\n",
              " 'n_iter_no_change': 5,\n",
              " 'n_jobs': None,\n",
              " 'penalty': 'l2',\n",
              " 'power_t': 0.5,\n",
              " 'random_state': None,\n",
              " 'shuffle': False,\n",
              " 'tol': 0.001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7VyGARmXiuX",
        "outputId": "bba60b0e-7f57-443f-aa94-16397e977349"
      },
      "source": [
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_test,y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9511784511784511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTZ7FezKRIqO",
        "outputId": "09ebebef-4128-4312-8f3d-e8a5ec945321"
      },
      "source": [
        "import scipy \n",
        "\n",
        "param_dist = {'penalty': ['l2','l1'],\n",
        "              'eta0': loguniform(1e-4, 1e-2),\n",
        "              'alpha': scipy.stats.expon(scale=.1)}\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 20\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search)\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=None, error_score=nan,\n",
              "                   estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                           class_weight=None,\n",
              "                                           early_stopping=False, epsilon=0.1,\n",
              "                                           eta0=0.0, fit_intercept=True,\n",
              "                                           l1_ratio=0.15,\n",
              "                                           learning_rate='optimal', loss='log',\n",
              "                                           max_iter=1000, n_iter_no_change=5,\n",
              "                                           n_jobs=None, penalty='l2',\n",
              "                                           power_t=0.5, random_state=None,\n",
              "                                           shuffle=False, tol=0.001,\n",
              "                                           validation_fract...\n",
              "                                           warm_start=False),\n",
              "                   iid='deprecated', n_iter=20, n_jobs=None,\n",
              "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2bfbdf7b50>,\n",
              "                                        'eta0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2bfbdf7990>,\n",
              "                                        'penalty': ['l2', 'l1']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqC6eeuWWAU2",
        "outputId": "21df0ace-c6da-4671-ba19-c0703e68f169"
      },
      "source": [
        "random_search.best_params_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.3006454950643594, 'eta0': 0.00014617560407750082, 'penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MAtGyM7WZsT",
        "outputId": "73b0c281-bf1e-4897-a662-1234985161cf"
      },
      "source": [
        "clf.set_params(**random_search.best_params_)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.3006454950643594, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.00014617560407750082,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=None, shuffle=False,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu06O6h1XO8R",
        "outputId": "ffc85464-242c-46b2-8e3c-a3ea1aec4252"
      },
      "source": [
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.3006454950643594, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.00014617560407750082,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=None, shuffle=False,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwXzbuXyXRIb",
        "outputId": "ce0cb764-9f62-4845-9d95-758df6678ef4"
      },
      "source": [
        "clf.score(X_test,y_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9629629629629629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBUr3n8cBx15",
        "outputId": "26e31d98-e0c6-424b-baae-22341220f6e8"
      },
      "source": [
        "from sklearn.model_selection import ParameterSampler\n",
        "\n",
        "def score(clf,X_train,y_train,X_test,y_test,par):\n",
        "  clf.set_params(**par)\n",
        "  clf.fit(X_train,y_train)\n",
        "  return clf.score(X_test,y_test)\n",
        "\n",
        "param_list = list(ParameterSampler(param_dist, n_iter=20))\n",
        "\n",
        "max_val=-np.infty\n",
        "min_val=np.infty\n",
        "for i,par in enumerate(param_list):\n",
        "  current_val=score(clf,X_train,y_train,X_test,y_test,par)\n",
        "  min_val=min(current_val,min_val)\n",
        "  max_val=max(current_val,max_val)\n",
        "  print('Parametro {0}, score : {1}'.format(i,current_val))\n",
        "\n",
        "print('min val {0}, max_val : {1}'.format(min_val,max_val))\n",
        " "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parametro 0, score : 0.9208754208754208\n",
            "Parametro 1, score : 0.9208754208754208\n",
            "Parametro 2, score : 0.9074074074074074\n",
            "Parametro 3, score : 0.7239057239057239\n",
            "Parametro 4, score : 0.8468013468013468\n",
            "Parametro 5, score : 0.877104377104377\n",
            "Parametro 6, score : 0.7676767676767676\n",
            "Parametro 7, score : 0.9175084175084175\n",
            "Parametro 8, score : 0.9595959595959596\n",
            "Parametro 9, score : 0.877104377104377\n",
            "Parametro 10, score : 0.9612794612794613\n",
            "Parametro 11, score : 0.898989898989899\n",
            "Parametro 12, score : 0.9074074074074074\n",
            "Parametro 13, score : 0.7626262626262627\n",
            "Parametro 14, score : 0.9545454545454546\n",
            "Parametro 15, score : 0.7491582491582491\n",
            "Parametro 16, score : 0.7861952861952862\n",
            "Parametro 17, score : 0.9326599326599326\n",
            "Parametro 18, score : 0.9191919191919192\n",
            "Parametro 19, score : 0.9629629629629629\n",
            "min val 0.7239057239057239, max_val : 0.9629629629629629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIb33O5Dcf8a"
      },
      "source": [
        "from sklearn.model_selection import ParameterSampler\n",
        "import copy \n",
        "\n",
        "def mutation(param_dist,par,prior=False):\n",
        "  new_par=copy.deepcopy(par) \n",
        "  param_to_update = np.random.choice(list(param_dist.keys()))\n",
        "  param_vals = param_dist[param_to_update]\n",
        "  if isinstance(param_vals,list):\n",
        "    new_par[param_to_update]=np.random.choice(param_vals)\n",
        "  else:\n",
        "    if prior:\n",
        "      new_par[param_to_update]=param_vals.rvs()\n",
        "    else:\n",
        "      new_par[param_to_update]=par[param_to_update]+np.abs(np.random.normal(0,1e-1))\n",
        "  return new_par\n",
        "\n",
        "param_list = list(ParameterSampler(param_dist, n_iter=1))"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXoFEPaET1S1",
        "outputId": "f4ed9917-97ef-4a22-a17b-a302fc9ef060"
      },
      "source": [
        "par=param_list[0]\n",
        "print(par)\n",
        "clf.set_params(**par)\n",
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_test,y_test)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 0.14671042776547744, 'eta0': 0.004621528670708173, 'penalty': 'l2'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9629629629629629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSXBeyBfUSAj",
        "outputId": "678380f7-1732-4192-b933-06308696a663"
      },
      "source": [
        "new_par=mutation(param_dist,par,prior=True)\n",
        "print(new_par)\n",
        "clf.set_params(**new_par)\n",
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_test,y_test)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "penalty\n",
            "{'alpha': 0.14671042776547744, 'eta0': 0.004621528670708173, 'penalty': 'l1'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8484848484848485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPmQ1dk_JfBf"
      },
      "source": [
        "import math\n",
        "\n",
        "class temperature_scheduling:\n",
        "    \n",
        "    def __init__(self,initial_temperature,min_temperature,gamma):\n",
        "        self.initial_temperature=initial_temperature\n",
        "        self.min_temperature=min_temperature\n",
        "        self.temperature=initial_temperature\n",
        "        self.gamma=gamma\n",
        "        \n",
        "    def exponential_decay(self):\n",
        "        self.temperature=self.gamma*self.temperature\n",
        "        return max(self.temperature,self.min_temperature)\n",
        "    \n",
        "    def fast_decay(self,k):\n",
        "        self.temperature=self.initial_temperature/k\n",
        "        return max(self.temperature,self.min_temperature)\n",
        "    \n",
        "    def logarithmic_decay(self,k):\n",
        "        self.temperature=self.initial_temperature*math.log(2,2)/math.log(k+1,2)\n",
        "        return max(self.temperature,self.min_temperature)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9djBBAP974e",
        "outputId": "835d2bfc-eec6-445b-ecc5-622b445bb9fb"
      },
      "source": [
        "k=0.85\n",
        "initial_temperature=1.2*(max_val-min_val)\n",
        "min_temp=1e-4\n",
        "\n",
        "par=param_list[0]\n",
        "temp=temperature_scheduling(initial_temperature,min_temp,k)\n",
        "current_val=score(clf,X_train,y_train,X_test,y_test,par)\n",
        "epochs=10\n",
        "loss=[]\n",
        "\n",
        "for i in range(1,epochs):\n",
        "    new_par=mutation(param_dist,par,prior=True)\n",
        "    next_value=score(clf,X_train,y_train,X_test,y_test,new_par)\n",
        "    delta = (current_val-next_value)\n",
        "    T=temp.logarithmic_decay(i)\n",
        "    if delta>0:\n",
        "        par=copy.deepcopy(new_par)\n",
        "    else:\n",
        "        alpha=min(1,np.exp(delta/T))\n",
        "        if alpha>np.random.random():\n",
        "            par=copy.deepcopy(new_par)\n",
        "            current_val=next_value\n",
        "    loss.append(current_val)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sIbC6NELZfV",
        "outputId": "4d82f3f9-021e-47be-aa78-3d9d815cd091"
      },
      "source": [
        "loss"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9494949494949495,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9629629629629629,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646,\n",
              " 0.9646464646464646]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    }
  ]
}